{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44d29af",
   "metadata": {},
   "source": [
    "# Data Science Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2cc6aa",
   "metadata": {},
   "source": [
    "Este código extrae info de los productos de la plataforma de Mercado Libre México para el analisis exploratorio de los productos con descuentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2ca7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82e846",
   "metadata": {},
   "source": [
    "Vemos las categorías que se tienen para la plataforma en México"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5034f2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de categorías: 31\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Obtener la lista de categorías para Mercado Libre México\n",
    "def get_mexico_categories():\n",
    "    url = \"https://api.mercadolibre.com/sites/MLM/categories\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        categories = response.json()\n",
    "        return [(category['id'], category['name']) for category in categories]\n",
    "    else:\n",
    "        print(\"Error al obtener las categorías:\", response.status_code)\n",
    "        return []\n",
    "\n",
    "# Ejemplo de uso\n",
    "categories = get_mexico_categories()\n",
    "print(f\"Total de categorías: {len(categories)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad279eb2",
   "metadata": {},
   "source": [
    "Está función a continuación nos permite extraer los datos de la API para el caso de México que nos permitirá hacer el analisis exploratorio de descuentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002efd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener productos por rango de precios y condición\n",
    "def fetch_products_by_price_and_condition(category_id, min_price, max_price, condition, max_pages=20):\n",
    "    base_url = \"https://api.mercadolibre.com/sites/MLM/search\"\n",
    "    all_results = []\n",
    "    items_per_page = 50\n",
    "    \n",
    "    for page in range(max_pages):\n",
    "        params = {\n",
    "            'category': category_id,\n",
    "            'price': f\"{min_price}-{max_price}\",\n",
    "            'condition': condition,\n",
    "            'limit': items_per_page,\n",
    "            'offset': page * items_per_page,\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            results = data.get('results', [])\n",
    "            for product in results:\n",
    "                # Extraer los detalles relevantes incluyendo sold_quantity\n",
    "                product_info = {\n",
    "                    'id': product.get('id'),\n",
    "                    'title': product.get('title'),\n",
    "                    'price': product.get('price'),\n",
    "                    'sold_quantity': product.get('sold_quantity'),\n",
    "                    'available_quantity': product.get('available_quantity'),\n",
    "                    'condition': product.get('condition'),\n",
    "                    'permalink': product.get('permalink'),\n",
    "                    'thumbnail': product.get('thumbnail'),\n",
    "                    'currency_id': product.get('currency_id'),\n",
    "                    'category_id': product.get('category_id'),\n",
    "                    'listing_type_id': product.get('listing_type_id'),\n",
    "                    'start_time': product.get('start_time'),\n",
    "                    'stop_time': product.get('stop_time'),\n",
    "                    'shipping': product.get('shipping'),\n",
    "                    'seller_id': product['seller'].get('id') if product.get('seller') else None,\n",
    "                    'seller_power_seller_status': product['seller'].get('power_seller_status') if product.get('seller') else None,\n",
    "                    'seller_registration_date': product['seller'].get('registration_date') if product.get('seller') else None,\n",
    "                    'video_id': product.get('video_id'),\n",
    "                    'warranty_time': product.get('warranty_time'),\n",
    "                    'health': product.get('health'),\n",
    "                    'pictures': product.get('pictures'),\n",
    "                    'descriptions': product.get('descriptions'),\n",
    "                    'sub_status': product.get('sub_status'),\n",
    "                    'site_id': product.get('site_id'),\n",
    "                    'geolocation': product.get('geolocation'),\n",
    "                    'international_delivery_mode': product.get('international_delivery_mode'),\n",
    "                    'catalog_product_id': product.get('catalog_product_id'),\n",
    "                    'secure_url': product.get('secure_url'),\n",
    "                    'automatic_relist': product.get('automatic_relist'),\n",
    "                    'accepts_mercadopago': product.get('accepts_mercadopago'),\n",
    "                    'deals': product.get('deals'),\n",
    "                    'deal_ids': product.get('deal_ids'),\n",
    "                    'seller_address': product.get('seller_address'),\n",
    "                    'tags': product.get('tags'),\n",
    "                    'subtitle': product.get('subtitle'),\n",
    "                    'logistic_type': product.get('logistic_type'),\n",
    "                    'warranty_type': product.get('warranty_type'),\n",
    "                    'seller_custom_field': product.get('seller_custom_field'),\n",
    "                    'variations': product.get('variations'),\n",
    "                    'sold_quantity_by_period': product.get('sold_quantity_by_period'),\n",
    "                    'order_backend': product.get('order_backend'),\n",
    "                    'thumbnail_url': product.get('thumbnail_url'),\n",
    "                    'differential_pricing_id': product.get('differential_pricing_id'),\n",
    "                    'stock': product.get('stock'),\n",
    "                    'installments.rate': product['installments'].get('rate') if product.get('installments') else None,\n",
    "                    'installments.amount': product['installments'].get('amount') if product.get('installments') else None,\n",
    "                    'installments.quantity': product['installments'].get('quantity') if product.get('installments') else None,\n",
    "                }\n",
    "    \n",
    "                all_results.append(product_info)\n",
    "            \n",
    "            if len(results) < items_per_page:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Error al obtener datos para categoría {category_id}: {response.status_code}\")\n",
    "            break\n",
    "            \n",
    "    return all_results\n",
    "\n",
    "# Función para iterar sobre categorías y almacenar datos por categoría\n",
    "def fetch_and_store_all_categories_products(categories, price_ranges, conditions, max_pages=20):\n",
    "    for category_id, category_name in categories:\n",
    "        print(f\"Fetching data for category: {category_name} (ID: {category_id})\")\n",
    "        \n",
    "        category_data = []\n",
    "        \n",
    "        for min_price, max_price in price_ranges:\n",
    "            for condition in conditions:\n",
    "                print(f\" - Price range: {min_price}-{max_price}, Condition: {condition}\")\n",
    "                products = fetch_products_by_price_and_condition(category_id, min_price, max_price, condition, max_pages=max_pages)\n",
    "                category_data.extend(products)\n",
    "        \n",
    "        # Convertir los datos a DataFrame\n",
    "        df = pd.DataFrame(category_data)\n",
    "        \n",
    "        # Crear un directorio para almacenar los archivos por categoría\n",
    "        category_dir = f\"data/{category_name}\"\n",
    "        os.makedirs(category_dir, exist_ok=True)\n",
    "        \n",
    "        # Guardar los datos en un archivo CSV por categoría\n",
    "        file_path = os.path.join(category_dir, f\"{category_name}_products.csv\")\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Data for category {category_name} saved to {file_path}\")\n",
    "\n",
    "# Definir los rangos de precios y condiciones\n",
    "price_ranges = [\n",
    "    (0, 5000),\n",
    "    (5001, 10000),\n",
    "    (10001, 20000),\n",
    "    (20001, 50000),\n",
    "    (50001, 10000000),\n",
    "]\n",
    "\n",
    "conditions = ['new', 'used']\n",
    "\n",
    "# Obtener la lista de categorías para Mercado Libre México\n",
    "categories = get_mexico_categories()\n",
    "\n",
    "# Obtener y almacenar productos por categorías con los criterios definidos\n",
    "fetch_and_store_all_categories_products(categories, price_ranges, conditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc35c0d",
   "metadata": {},
   "source": [
    "Cargamos todos los datos en un solo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e852b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Función para verificar si un archivo está vacío\n",
    "def is_file_empty(file_path):\n",
    "    return os.path.getsize(file_path) == 0\n",
    "\n",
    "# Función para leer archivos CSV de cada categoría y combinarlos en un solo DataFrame\n",
    "def load_and_combine_data(data_dir):\n",
    "    combined_df = pd.DataFrame()  # DataFrame vacío para combinar todos los datos\n",
    "    \n",
    "    # Iterar sobre todas las carpetas en el directorio de datos\n",
    "    for category_name in os.listdir(data_dir):\n",
    "        category_dir = os.path.join(data_dir, category_name)\n",
    "        \n",
    "        if os.path.isdir(category_dir):  # Verifica si es un directorio\n",
    "            # Buscar archivos CSV en la carpeta de la categoría\n",
    "            for file_name in os.listdir(category_dir):\n",
    "                if file_name.endswith('.csv'):\n",
    "                    file_path = os.path.join(category_dir, file_name)\n",
    "                    \n",
    "                    # Verificar si el archivo está vacío\n",
    "                    if is_file_empty(file_path):\n",
    "                        print(f\"Archivo vacío: {file_path}, saltando...\")\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # Leer el archivo CSV\n",
    "                        df = pd.read_csv(file_path)\n",
    "                        \n",
    "                        # Agregar una columna con el nombre de la categoría\n",
    "                        df['category'] = category_name\n",
    "                        \n",
    "                        # Combinar con el DataFrame principal\n",
    "                        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "                    except pd.errors.EmptyDataError:\n",
    "                        print(f\"Error: El archivo {file_path} está vacío o no contiene datos válidos.\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Directorio donde están almacenados los archivos por categorías\n",
    "data_dir = 'data'\n",
    "\n",
    "# Cargar y combinar todos los datos\n",
    "all_products_df = load_and_combine_data(data_dir)\n",
    "\n",
    "# Opcional: Guardar el DataFrame combinado en un nuevo archivo CSV\n",
    "all_products_df.to_csv('mercado_libre_all_combined.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9f81ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86287, 39)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_products_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410663a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5047"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_products_df[lambda x:x.original_price.notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ab0b1",
   "metadata": {},
   "source": [
    "Leemos los datos que obtuvimos del otro repo en la carpeta data_prov y lo combinamos en uno solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22484508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/31] Archivo 'MCO1368.csv' cargado satisfactoriamente.\n",
      "[2/31] Archivo 'MCO3025.csv' cargado satisfactoriamente.\n",
      "[3/31] Archivo 'MCO1168.csv' cargado satisfactoriamente.\n",
      "[4/31] Archivo 'MCO1430.csv' cargado satisfactoriamente.\n",
      "[5/31] Archivo 'MCO1747.csv' cargado satisfactoriamente.\n",
      "[6/31] Archivo 'MCO1182.csv' cargado satisfactoriamente.\n",
      "[7/31] Archivo 'MCO1384.csv' cargado satisfactoriamente.\n",
      "[8/31] Archivo 'MCO1743.csv' cargado satisfactoriamente.\n",
      "[9/31] Archivo 'MCO1540.csv' cargado satisfactoriamente.\n",
      "[10/31] Archivo 'MCO5726.csv' cargado satisfactoriamente.\n",
      "[11/31] Archivo 'MCO1144.csv' cargado satisfactoriamente.\n",
      "[12/31] Archivo 'MCO118204.csv' cargado satisfactoriamente.\n",
      "[13/31] Archivo 'MCO441917.csv' cargado satisfactoriamente.\n",
      "[14/31] Archivo 'MCO1132.csv' cargado satisfactoriamente.\n",
      "[15/31] Archivo 'MCO1051.csv' cargado satisfactoriamente.\n",
      "[16/31] Archivo 'MCO1246.csv' cargado satisfactoriamente.\n",
      "[17/31] Archivo 'MCO1459.csv' cargado satisfactoriamente.\n",
      "[18/31] Archivo 'MCO1276.csv' cargado satisfactoriamente.\n",
      "[19/31] Archivo 'MCO40433.csv' cargado satisfactoriamente.\n",
      "[20/31] Archivo 'MCO1499.csv' cargado satisfactoriamente.\n",
      "[21/31] Archivo 'MCO3937.csv' cargado satisfactoriamente.\n",
      "[22/31] Archivo 'MCO1648.csv' cargado satisfactoriamente.\n",
      "[23/31] Archivo 'MCO180800.csv' cargado satisfactoriamente.\n",
      "[24/31] Archivo 'MCO1071.csv' cargado satisfactoriamente.\n",
      "[25/31] Archivo 'MCO175794.csv' cargado satisfactoriamente.\n",
      "[26/31] Archivo 'MCO1000.csv' cargado satisfactoriamente.\n",
      "[27/31] Archivo 'MCO1574.csv' cargado satisfactoriamente.\n",
      "[28/31] Archivo 'MCO1039.csv' cargado satisfactoriamente.\n",
      "[29/31] Archivo 'MCO1367.csv' cargado satisfactoriamente.\n",
      "[30/31] Archivo 'MCO1403.csv' cargado satisfactoriamente.\n",
      "[31/31] Archivo 'MCO1953.csv' cargado satisfactoriamente.\n",
      "Todos los archivos se han combinado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Directorio\n",
    "carpeta = os.path.expanduser('~/Documents/busqueda_chambi/2024/meli_no_repo/data_prov')\n",
    "archivos_csv = [f for f in os.listdir(carpeta) if f.endswith('.csv')]\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "# Progreso total\n",
    "total_archivos = len(archivos_csv)\n",
    "\n",
    "for i, archivo in enumerate(archivos_csv, start=1):\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(carpeta, archivo), sep=';', encoding='utf-8')\n",
    "        dataframes.append(df)\n",
    "        print(f\"[{i}/{total_archivos}] Archivo '{archivo}' cargado satisfactoriamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{i}/{total_archivos}] Error al cargar '{archivo}': {e}\")\n",
    "\n",
    "df_combinado = pd.concat(dataframes, ignore_index=True)\n",
    "print(\"Todos los archivos se han combinado exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961bd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combinado.to_csv(\"df_model_comb.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2107db6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import session_info\n",
    "session_info.show(html=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
